{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# SKLearn related imports\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's look at some Movie Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment    object\n",
       "Text         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/imdb_sentiment.csv')\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Note to all mad scientists everywhere: if you'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>If you go to this movie expecting something it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>How this film gains a 6.7 rating is beyond bel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just got through watching this version of \"Sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Zombi 3 starts as a group of heavily armed men...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                               Text\n",
       "0  Negative  Note to all mad scientists everywhere: if you'...\n",
       "1  Positive  If you go to this movie expecting something it...\n",
       "2  Negative  How this film gains a 6.7 rating is beyond bel...\n",
       "3  Positive  Just got through watching this version of \"Sam...\n",
       "4  Negative  Zombi 3 starts as a group of heavily armed men..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If you go to this movie expecting something it isn\\'t, you will be disappointed, as with any movie. This movie contains what Hemmingway described as the \"iceberg effect\". On the surface, its simply a cache of random movie clips smashed together to make a movie. If this would be written in a book, it would be a short story, because the action in the movie is very fast paced, and unless you actually try to catch it, the reasoning behind the plot (along with some subtle foreshadowing) can very well pass you by. Definitely a movie you will have to see twice in order to fully appreciate. Experimental Cinematography barely describes this movie. The camera-work and post production add much to the overall flavour of the film, making it quite artistic at some points and open to interpretation at others (something to be desired in American movies as of late). Although, at some parts it may get a little raunchy, gruesome and too heavy for some audiences, the movie never becomes completely unrealistic. The only aspect of the movie that I would write off as \"needs improvement\" is the soundtrack selection. No movie is ever good without a fitting soundtrack, and although the soundtrack is quite fitting, the opening is a little too long, and the other rap songs in the film really could have been replaced with something more appropriate (heavy, grungy rock or psychedelic electronica would have made this film a real trip). The flooding of imagery and dynamic... color palettes adds another \"artistic\" aspect to it, also combined with the events that happen throughout the film, this is not a movie you can miss any part of and still understand. However, that also makes it much more of a desirable film to watch, and not one you\\'ll quickly get bored of. 8.5/10'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in train and validation\n",
    "train_df, validation_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representing Text through a Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small sample of the vocabulary: ['marvellous', 'beingness', 'lynched', 'masculine', 'galvanized', 'glitters', 'industrial', 'presumptive', 'anticlimactic', 'teamo', 'harry', 'tnn', 'pyun', 'clamour', 'lucian', 'boilers', 'tumbuan', 'calomari', 'intruded', 'jovial']\n",
      "\n",
      "Number of distinct words: 68587\n"
     ]
    }
   ],
   "source": [
    "vectorizer.fit(train_df['Text'].values)\n",
    "\n",
    "# Looking at a small sample of the vocabulary:\n",
    "vocabulary = list(vectorizer.vocabulary_.keys())\n",
    "print(\"Small sample of the vocabulary:\", vocabulary[0:20])\n",
    "\n",
    "# Number of words in the vocabulary\n",
    "print(\"\\nNumber of distinct words:\", len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A phenomenal achievement in awfulness. It's actually hilariously awful.<br /><br />First off...Nicholas Cage must now have made it to the finals in the Over-Emoting Category in his acting class. Wearing new hair plugs and with a face that has been lifted so many times his pinned back ears seem to be straining to touch in the back he oozes not only a sick smarmiess but creates a \"hero\" character that you have no vested interest in.<br /><br />I don't know what it is with Neil Labute and female characters. He makes females out to be totally deviant and evil...and pays them back by having Cage punch several of them directly in the face and call them all \"b****es\" a few times too. I've enjoyed LaBute's early films and a few of his plays...but it's a strange fascination he has.<br /><br />I'd give this film a 2 out of 10 solely based on Ellen Burstyn's performance. By the time she finally makes her appearance (bravely soldiering through her scenes with her wig line clearly visible on her forehead) it seems like all hope may be lost. She deserves an Oscar right here and now for saying her lines with a straight face and when she appears wearing a white mumu and blue, white, and gold face paint booming about The Wicker Man you know that working with Scorcese and Friedkin really prepped her for this role dang well.<br /><br />This movie is so wrong-headed and cuckoo that is has to be seen to be believed.<br /><br />Highlights include: Nicholas Cage running away from a swarm of bees and then falling down a hill.<br /><br />Nicholas Cage stealing a bicycle and looking like Ms. Gulch from The Wizard of Oz riding around on it.<br /><br />Nicholas Cage running around the island kicking down doors looking for the missing girl.<br /><br />Leelee Sobieski PLUMMETING from a once-promising acting career in a \"brawl\" with Cage.<br /><br />Ellen Burstyn dancing around in a said while mumu.<br /><br />Nicholas Cage screaming \"Who burned it? Who burned it? Who burned it?Who burned it?Who burned it?Who burned it?\" for no reason.<br /><br />Nicholas Cage in a bear costume (I'm not kidding) running through the woods, taking off the costume (but leaving the bear feet on) and then doing some karate moves to some villains.<br /><br />And you haven't lived until you have seen the final 15 minutes of the movie and its dreadful epilogue that looked like it was shot yesterday in your cousin's basement.<br /><br />Needless to say, if you can make it through this film without laughing out loud then you deserve a medal. There was actually a point in the movie where I stopped snickering to wonder if maybe this wasn't an elaborate send-up of \"hysteria\" films...only to be reminded when Cage would scream/shout/whisper his dialogue that he really was taking himself quite seriously.<br /><br />I think this one is destined to be a cult film all over again...just because it's so dreadful. \n",
      "\n",
      "10 :  1\n",
      "15 :  1\n",
      "about :  1\n",
      "achievement :  1\n",
      "acting :  2\n",
      "actually :  2\n",
      "again :  1\n",
      "all :  3\n",
      "an :  2\n",
      "and :  17\n",
      "appearance :  1\n",
      "appears :  1\n",
      "around :  3\n",
      "away :  1\n",
      "awful :  1\n",
      "awfulness :  1\n",
      "back :  3\n",
      "based :  1\n",
      "basement :  1\n",
      "be :  7\n",
      "bear :  2\n",
      "because :  1\n",
      "been :  1\n",
      "bees :  1\n",
      "believed :  1\n",
      "bicycle :  1\n",
      "blue :  1\n",
      "booming :  1\n",
      "br :  28\n",
      "bravely :  1\n",
      "brawl :  1\n",
      "burned :  6\n",
      "burstyn :  2\n",
      "but :  3\n",
      "by :  2\n",
      "cage :  9\n",
      "call :  1\n",
      "can :  1\n",
      "career :  1\n",
      "category :  1\n",
      "character :  1\n",
      "characters :  1\n",
      "class :  1\n",
      "clearly :  1\n",
      "costume :  2\n",
      "cousin :  1\n",
      "creates :  1\n",
      "cuckoo :  1\n",
      "cult :  1\n",
      "dancing :  1\n",
      "dang :  1\n",
      "deserve :  1\n",
      "deserves :  1\n",
      "destined :  1\n",
      "deviant :  1\n",
      "dialogue :  1\n",
      "directly :  1\n",
      "doing :  1\n",
      "don :  1\n",
      "doors :  1\n",
      "down :  2\n",
      "dreadful :  2\n",
      "early :  1\n",
      "ears :  1\n",
      "elaborate :  1\n",
      "ellen :  2\n",
      "emoting :  1\n",
      "enjoyed :  1\n",
      "epilogue :  1\n",
      "es :  1\n",
      "evil :  1\n",
      "face :  4\n",
      "falling :  1\n",
      "fascination :  1\n",
      "feet :  1\n",
      "female :  1\n",
      "females :  1\n",
      "few :  2\n",
      "film :  3\n",
      "films :  2\n",
      "final :  1\n",
      "finally :  1\n",
      "finals :  1\n",
      "first :  1\n",
      "for :  4\n",
      "forehead :  1\n",
      "friedkin :  1\n",
      "from :  3\n",
      "girl :  1\n",
      "give :  1\n",
      "gold :  1\n",
      "gulch :  1\n",
      "hair :  1\n",
      "has :  3\n",
      "have :  3\n",
      "haven :  1\n",
      "having :  1\n",
      "he :  4\n",
      "headed :  1\n",
      "her :  6\n",
      "here :  1\n",
      "hero :  1\n",
      "highlights :  1\n",
      "hilariously :  1\n",
      "hill :  1\n",
      "himself :  1\n",
      "his :  4\n",
      "hope :  1\n",
      "hysteria :  1\n",
      "if :  2\n",
      "in :  11\n",
      "include :  1\n",
      "interest :  1\n",
      "is :  4\n",
      "island :  1\n",
      "it :  15\n",
      "its :  1\n",
      "just :  1\n",
      "karate :  1\n",
      "kicking :  1\n",
      "kidding :  1\n",
      "know :  2\n",
      "labute :  2\n",
      "laughing :  1\n",
      "leaving :  1\n",
      "leelee :  1\n",
      "lifted :  1\n",
      "like :  3\n",
      "line :  1\n",
      "lines :  1\n",
      "lived :  1\n",
      "looked :  1\n",
      "looking :  2\n",
      "lost :  1\n",
      "loud :  1\n",
      "made :  1\n",
      "make :  1\n",
      "makes :  2\n",
      "man :  1\n",
      "many :  1\n",
      "may :  1\n",
      "maybe :  1\n",
      "medal :  1\n",
      "minutes :  1\n",
      "missing :  1\n",
      "moves :  1\n",
      "movie :  3\n",
      "ms :  1\n",
      "mumu :  2\n",
      "must :  1\n",
      "needless :  1\n",
      "neil :  1\n",
      "new :  1\n",
      "nicholas :  6\n",
      "no :  2\n",
      "not :  2\n",
      "now :  2\n",
      "of :  7\n",
      "off :  2\n",
      "on :  4\n",
      "once :  1\n",
      "one :  1\n",
      "only :  2\n",
      "oozes :  1\n",
      "oscar :  1\n",
      "out :  3\n",
      "over :  2\n",
      "oz :  1\n",
      "paint :  1\n",
      "pays :  1\n",
      "performance :  1\n",
      "phenomenal :  1\n",
      "pinned :  1\n",
      "plays :  1\n",
      "plugs :  1\n",
      "plummeting :  1\n",
      "point :  1\n",
      "prepped :  1\n",
      "promising :  1\n",
      "punch :  1\n",
      "quite :  1\n",
      "really :  2\n",
      "reason :  1\n",
      "reminded :  1\n",
      "riding :  1\n",
      "right :  1\n",
      "role :  1\n",
      "running :  3\n",
      "said :  1\n",
      "say :  1\n",
      "saying :  1\n",
      "scenes :  1\n",
      "scorcese :  1\n",
      "scream :  1\n",
      "screaming :  1\n",
      "seem :  1\n",
      "seems :  1\n",
      "seen :  2\n",
      "send :  1\n",
      "seriously :  1\n",
      "several :  1\n",
      "she :  3\n",
      "shot :  1\n",
      "shout :  1\n",
      "sick :  1\n",
      "smarmiess :  1\n",
      "snickering :  1\n",
      "so :  3\n",
      "sobieski :  1\n",
      "soldiering :  1\n",
      "solely :  1\n",
      "some :  2\n",
      "stealing :  1\n",
      "stopped :  1\n",
      "straight :  1\n",
      "straining :  1\n",
      "strange :  1\n",
      "swarm :  1\n",
      "taking :  2\n",
      "that :  6\n",
      "the :  15\n",
      "them :  3\n",
      "then :  3\n",
      "there :  1\n",
      "think :  1\n",
      "this :  6\n",
      "through :  3\n",
      "time :  1\n",
      "times :  2\n",
      "to :  11\n",
      "too :  1\n",
      "totally :  1\n",
      "touch :  1\n",
      "until :  1\n",
      "up :  1\n",
      "ve :  1\n",
      "vested :  1\n",
      "villains :  1\n",
      "visible :  1\n",
      "was :  3\n",
      "wasn :  1\n",
      "wearing :  2\n",
      "well :  1\n",
      "what :  1\n",
      "when :  2\n",
      "where :  1\n",
      "while :  1\n",
      "whisper :  1\n",
      "white :  2\n",
      "who :  6\n",
      "wicker :  1\n",
      "wig :  1\n",
      "with :  6\n",
      "without :  1\n",
      "wizard :  1\n",
      "wonder :  1\n",
      "woods :  1\n",
      "working :  1\n",
      "would :  1\n",
      "wrong :  1\n",
      "yesterday :  1\n",
      "you :  6\n",
      "your :  1\n"
     ]
    }
   ],
   "source": [
    "sentence = train_df['Text'].values[12:13]\n",
    "print(sentence[0], '\\n')\n",
    "\n",
    "# Tranform sentence into bag of words representation\n",
    "word_count_sentence = vectorizer.transform(sentence)\n",
    "\n",
    "# Find the indexes of the words which appear in the sentence\n",
    "_, columns = word_count_sentence.nonzero()\n",
    "\n",
    "# Get the inverse map to map vector indexes to words\n",
    "vocabulary = vectorizer.vocabulary_\n",
    "inv_map = {v: k for k, v in vocabulary.items()}\n",
    "\n",
    "# Extract the corresponding word and count\n",
    "counts = [(inv_map[i], word_count_sentence[0, i]) for i in columns]\n",
    "\n",
    "for word, count in counts:\n",
    "    print(word, \": \", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 68587)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_matrix = vectorizer.transform(train_df['Text'].values)\n",
    "word_count_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kicking it up a notch with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "tfidf.fit(word_count_matrix)\n",
    "\n",
    "word_term_frequency_matrix = tfidf.transform(word_count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20000x68587 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2763676 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_term_frequency_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
